---
layout: post
title: Spark Study (2) - RDD(Resilent Distributed Dataset)란?
tags: [spark]
comments: true
---

[이전 포스트](https://fluxus-dev.github.io/2019-03-26-spark1/)에서 Spark의 개요에 대해서 정리하였다.
하지만 RDD에 대하여 알지 못한다면 Spark를 안다고 할 수 없다.
그러니 이번 기회에 RDD에 대해서 자세히 정리해보자.

### RDD 이전의 대용량 데이터 처리 - MapReduce
RDD를 사용하기 이전엔 빅데이터 처리를 위하여 Hadoop의 MapReduce를 주로 사용하였다.
MapReduce는 간단하게 Map과 Reduce 함수의 줄인말이며 각각 다음과 같다.
- Map : Key, value 형태의 자료구조
- Reduce : Map을 집계하는 함수

MapReduce에 대하여 더 상세히 정리할 수도 있겠지만, MapReduce의 속도적 한계로 인해 Spark의 RDD가 부상하게 된 것이기에 한계점만 기술하고자 한다.


> MapReduce의 한계
> - 복잡한 처리가 어려움(머신러닝, 그래프 등)
> - Ad-hoc 쿼리 처리 어려움
>     
>원인
> - 데이터 처리 각 단계마다 HDFS에 반복해서 Read, Write 하여 처리 → 속도 저하로 인해 복잡한 함수 적용 불가
>
> 해결방안
> - HDFS보다 빠른 RAM으로 대체하자!

### RDD란?
현재 3780회 인용된 전설적인 논문인 
Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing 
([PDF링크](https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf))
이 2012 소개되며 Spark 전성시대의 서막이 올랐다.

우선 논문에서 소개하는 RDD를 각 단어별로 살펴보자.
 1. Resilient(탄력적인) : 장애가 발생하더라도 원상 복귀가 가능하며
 2. Distributed(분산된) : 분산 컴퓨팅 시스템의 메모리를 활용하여 데이터를 분산처리하는
 3. Dataset : 데이터의 모음!
 
 기존의 RAM 데이터 프로세싱과 비교해 보자.
 Picolo와 같은 RAM 프로세서들은 RAM의 특성상 데이터의 update 기능을 지원하는 경향이 있었다.
 그러나 이러한 update 기능을 제공하면서 Resilient한 데이터를 제공하기 위해서는
 1. 데이터의 복제 : 하나의 파티션에 장애가 발생해도 문제가 없도록 파티션을 복사해 두어야 하고, 복사를 하는 동안에 update가 발생하면 안되므로 중단 필요.(속도의 저하)
 2. Checkpointing : 복제만으로는 불완전하므로 상태를 스냅샷으로 디스크에 checkpointing. (디스크 IO로 인한 속도의 저하)
 
 *따라서 RDD는 update를 과감히 포기하고, RAM을 Read-only로만 사용하여 빠른 속도를 제공한다.*
 
 
>RDD의 주요 특징
> - Immutable(=read-only)
> - Fault-tolerant : Immutable 하기 때문에 부모로부터 어떻게 만들어졌는지 Lineage(계보)만 기록하면 Fault-tolerant 보장 가능.
> - Lazy Execution : 기존 RDD 데이터를 변환하여 새로운 RDD를 생성 시 실제 계산은 이루어지지 않고 Lineage만 생성됨. 실제로 계산이 이루어지는 시기는 마지막의 Action 명령어가 들어올 때!
 