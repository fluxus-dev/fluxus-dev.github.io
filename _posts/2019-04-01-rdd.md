---
layout: post
title: Spark Study (2) - RDD(Resilent Distributed Dataset)란?
tags: [spark]
comments: true
---

[이전 포스트](https://fluxus-dev.github.io/2019-03-26-spark1/)에서 Spark의 개요에 대해서 정리하였다.
하지만 RDD에 대하여 알지 못한다면 Spark를 안다고 할 수 없다.
그러니 이번 기회에 RDD에 대해서 자세히 정리해보자.

### RDD 이전의 대용량 데이터 처리 - MapReduce
RDD를 사용하기 이전엔 빅데이터 처리를 위하여 Hadoop의 MapReduce를 주로 사용하였다.
MapReduce는 간단하게 Map과 Reduce 함수의 줄인말이며 각각 다음과 같다.
- Map : Key, value 형태의 자료구조
- Reduce : Map을 집계하는 함수

MapReduce에 대하여 더 상세히 정리할 수도 있겠지만, MapReduce의 속도적 한계로 인해 Spark의 RDD가 부상하게 된 것이기에 한계점만 기술하고자 한다.
####MapReduce의 한계
- 복잡한 처리가 어려움(머신러닝, 그래프 등)
- Ad-hoc 쿼리 처리 어려움
#####원인
- 데이터 처리 각 단계마다 HDFS에 반복해서 Read, Write 하여 처리 → 속도 저하
#####해결방안
- HDFS보다 빠른 RAM으로 대체하자!

### RDD란?
2012년. 현재 3780회 인용된 전설적인 논문인 
Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing 
([PDF링크](https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf))
이 소개되며 Spark 전성시대의 서막이 올랐다.

우선 논문에서 소개하는 RDD를 각 단어별로 살펴보자.
 1. Resilient(탄력적인) : 장애가 발생하더라도 원상 복귀가 가능하며
 2. Distributed(분산된) : 분산 컴퓨팅 시스템의 메모리를 활용하여 데이터를 분산처리하는
 3. Dataset : 데이터의 모음!
               